# 微积分知识点整理（PyTorch版）

## 1. 微积分的起源与应用

### 知识点
- **积分**起源于古希腊的逼近法（method of exhaustion），通过内接多边形逼近曲线面积
- **微分**主要应用于优化问题，在深度学习中用于最小化损失函数
- 深度学习的两个核心问题：**优化**（用模型拟合观测数据）和**泛化**（模型在未见数据上的表现）

### 例子
古希腊人计算圆的面积：用正多边形内接于圆，边数越多越接近真实面积。现代深度学习中，我们通过梯度下降不断调整参数来最小化损失函数。

## 2. 导数和微分

### 知识点
导数定义：如果函数 $f$ 的导数存在，则：
$$f'(x) = \lim_{h \rightarrow 0} \frac{f(x+h) - f(x)}{h}$$

导数表示函数在某点的瞬时变化率，几何意义是切线斜率。

### 例子
```python
%matplotlib inline
from d2l import torch as d2l
from matplotlib_inline import backend_inline
import numpy as np

def f(x):
    return 3 * x ** 2 - 4 * x

def numerical_lim(f, x, h):
    return (f(x + h) - f(x)) / h

# 数值验证导数
h = 0.1
for i in range(5):
    print(f'h={h:.5f}, numerical limit={numerical_lim(f, 1, h):.5f}')
    h *= 0.1
```

对于 $f(x) = 3x^2 - 4x$，在 $x=1$ 处的导数为 $f'(1) = 6(1) - 4 = 2$。

## 3. 基本求导法则

### 知识点
- **常数法则**: $DC = 0$
- **幂律**: $Dx^n = nx^{n-1}$
- **指数函数**: $De^x = e^x$
- **对数函数**: $D\ln(x) = 1/x$

### 例子
计算 $g(x) = 2x^3 + e^x - 5$ 的导数：
$$g'(x) = 2 \cdot 3x^2 + e^x - 0 = 6x^2 + e^x$$

## 4. 复合函数求导法则

### 知识点
- **常数相乘法则**: $\frac{d}{dx}[Cf(x)] = C\frac{d}{dx}f(x)$
- **加法法则**: $\frac{d}{dx}[f(x) + g(x)] = f'(x) + g'(x)$
- **乘法法则**: $\frac{d}{dx}[f(x)g(x)] = f'(x)g(x) + f(x)g'(x)$
- **除法法则**: $\frac{d}{dx}\left[\frac{f(x)}{g(x)}\right] = \frac{f'(x)g(x) - f(x)g'(x)}{[g(x)]^2}$

### 例子
计算 $h(x) = x^2 \sin(x)$ 的导数（乘法法则）：
$$h'(x) = 2x \sin(x) + x^2 \cos(x)$$

## 5. 函数可视化

### 知识点
使用 matplotlib 可视化函数及其切线，帮助理解导数的几何意义。

### 例子
```python
def use_svg_display():  #@save
    """使用svg格式在Jupyter中显示绘图"""
    backend_inline.set_matplotlib_formats('svg')

def set_figsize(figsize=(3.5, 2.5)):  #@save
    """设置matplotlib的图表大小"""
    use_svg_display()
    d2l.plt.rcParams['figure.figsize'] = figsize

def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):
    """设置matplotlib的轴"""
    axes.set_xlabel(xlabel)
    axes.set_ylabel(ylabel)
    axes.set_xscale(xscale)
    axes.set_yscale(yscale)
    axes.set_xlim(xlim)
    axes.set_ylim(ylim)
    if legend:
        axes.legend(legend)
    axes.grid()

def plot(X, Y=None, xlabel=None, ylabel=None, legend=None, xlim=None,
         ylim=None, xscale='linear', yscale='linear',
         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):
    """绘制数据点"""
    if legend is None:
        legend = []

    set_figsize(figsize)
    axes = axes if axes else d2l.plt.gca()

    def has_one_axis(X):
        return (hasattr(X, "ndim") and X.ndim == 1 or isinstance(X, list)
                and not hasattr(X[0], "__len__"))

    if has_one_axis(X):
        X = [X]
    if Y is None:
        X, Y = [[]] * len(X), X
    elif has_one_axis(Y):
        Y = [Y]
    if len(X) != len(Y):
        X = X * len(Y)
    axes.cla()
    for x, y, fmt in zip(X, Y, fmts):
        if len(x):
            axes.plot(x, y, fmt)
        else:
            axes.plot(y, fmt)
    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)

# 绘制函数及其切线
x = np.arange(0, 3, 0.1)
plot(x, [f(x), 2 * x - 3], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)'])
```

## 6. 偏导数

### 知识点
对于多元函数 $y = f(x_1, x_2, \ldots, x_n)$，关于第 $i$ 个变量的偏导数为：
$$\frac{\partial y}{\partial x_i} = \lim_{h \rightarrow 0} \frac{f(x_1, \ldots, x_i+h, \ldots, x_n) - f(x_1, \ldots, x_i, \ldots, x_n)}{h}$$

计算偏导数时，将其他变量视为常数。

### 例子
对于函数 $f(x, y) = x^2y + 3xy^2$：
- $\frac{\partial f}{\partial x} = 2xy + 3y^2$
- $\frac{\partial f}{\partial y} = x^2 + 6xy$

## 7. 梯度

### 知识点
函数 $f(\mathbf{x})$ 相对于向量 $\mathbf{x}=[x_1,x_2,\ldots,x_n]^T$ 的梯度是包含所有偏导数的向量：
$$\nabla_{\mathbf{x}} f(\mathbf{x}) = \left[\frac{\partial f(\mathbf{x})}{\partial x_1}, \frac{\partial f(\mathbf{x})}{\partial x_2}, \ldots, \frac{\partial f(\mathbf{x})}{\partial x_n}\right]^T$$

### 例子
对于函数 $f(\mathbf{x}) = 3x_1^2 + 5e^{x_2}$：
$$\nabla f(\mathbf{x}) = \begin{bmatrix} 6x_1 \\ 5e^{x_2} \end{bmatrix}$$

## 8. 梯度的重要性质

### 知识点
- $\nabla_{\mathbf{x}} \mathbf{A} \mathbf{x} = \mathbf{A}^T$
- $\nabla_{\mathbf{x}} \mathbf{x}^T \mathbf{A} = \mathbf{A}$
- $\nabla_{\mathbf{x}} \mathbf{x}^T \mathbf{A} \mathbf{x} = (\mathbf{A} + \mathbf{A}^T)\mathbf{x}$
- $\nabla_{\mathbf{x}} \|\mathbf{x}\|^2 = 2\mathbf{x}$

### 例子
对于二次型 $f(\mathbf{x}) = \mathbf{x}^T\mathbf{A}\mathbf{x}$，其中 $\mathbf{A} = \begin{bmatrix} 2 & 1 \\ 1 & 3 \end{bmatrix}$：
$$\nabla f(\mathbf{x}) = (\mathbf{A} + \mathbf{A}^T)\mathbf{x} = \begin{bmatrix} 4 & 2 \\ 2 & 6 \end{bmatrix}\mathbf{x}$$

## 9. 链式法则

### 知识点
**单变量情况**: 若 $y=f(u)$ 和 $u=g(x)$ 都可微，则：
$$\frac{dy}{dx} = \frac{dy}{du} \frac{du}{dx}$$

**多变量情况**: 若 $y$ 依赖于 $u_1, \ldots, u_m$，每个 $u_i$ 依赖于 $x_1, \ldots, x_n$，则：
$$\frac{\partial y}{\partial x_i} = \sum_{j=1}^{m} \frac{\partial y}{\partial u_j} \frac{\partial u_j}{\partial x_i}$$

### 例子
计算复合函数 $y = \sin(x^2 + 1)$ 的导数：
- 令 $u = x^2 + 1$，则 $y = \sin(u)$
- $\frac{dy}{dx} = \frac{dy}{du} \frac{du}{dx} = \cos(u) \cdot 2x = 2x\cos(x^2 + 1)$

## 10. 练习题解答

### 练习1: 绘制 $y = x^3 - \frac{1}{x}$ 及其在 $x=1$ 处的切线

```python
def g(x):
    return x ** 3 - 1 / x

# 计算在x=1处的导数: g'(x) = 3x^2 + 1/x^2, g'(1) = 3 + 1 = 4
# 切点: (1, 0), 切线方程: y = 4(x-1) = 4x - 4

x = np.arange(0.1, 3, 0.1)
plot(x, [g(x), 4 * x - 4], 'x', 'y', legend=['y=x³-1/x', 'Tangent line (x=1)'])
```

### 练习2: 求 $f(\mathbf{x}) = 3x_1^2 + 5e^{x_2}$ 的梯度
$$\nabla f(\mathbf{x}) = \begin{bmatrix} 6x_1 \\ 5e^{x_2} \end{bmatrix}$$

### 练习3: 求 $f(\mathbf{x}) = \|\mathbf{x}\|_2$ 的梯度
$$\nabla f(\mathbf{x}) = \frac{\mathbf{x}}{\|\mathbf{x}\|_2}$$

### 练习4: 链式法则 $u = f(x, y, z)$，其中 $x = x(a, b)$，$y = y(a, b)$，$z = z(a, b)$
$$\frac{\partial u}{\partial a} = \frac{\partial u}{\partial x}\frac{\partial x}{\partial a} + \frac{\partial u}{\partial y}\frac{\partial y}{\partial a} + \frac{\partial u}{\partial z}\frac{\partial z}{\partial a}$$
$$\frac{\partial u}{\partial b} = \frac{\partial u}{\partial x}\frac{\partial x}{\partial b} + \frac{\partial u}{\partial y}\frac{\partial y}{\partial b} + \frac{\partial u}{\partial z}\frac{\partial z}{\partial b}$$