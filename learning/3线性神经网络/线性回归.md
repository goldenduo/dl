# 线性回归详解

## 什么是回归？

回归是一种建模方法，用来找出**输入变量**和**输出变量**之间的关系。简单来说，就是通过已知的数据来预测未知的结果。

**回归 vs 分类的区别：**
- **回归**：预测连续的数值（如房价、股价、温度）
- **分类**：预测离散的类别（如是否患病、邮件是否为垃圾邮件）

## 线性回归的核心思想

线性回归是最简单、最常用的回归方法，它的核心假设是：**输入和输出之间存在线性关系**。

### 用房价预测来理解

假设我们想根据房屋的**面积**和**房龄**来预测**房价**：

```
房价 = 权重1 × 面积 + 权重2 × 房龄 + 偏置
```

这就像一个简单的数学公式，其中：
- **权重**（weight）：决定每个因素的重要程度
- **偏置**（bias）：基础价格，即使面积和房龄都为0时的预测值

## 关键术语解释

| 术语    | 英文               | 含义          | 举例        |
|-------|------------------|-------------|-----------|
| 训练数据集 | Training Dataset | 用来训练模型的历史数据 | 过去的房屋交易记录 |
| 样本    | Sample           | 数据集中的每一条记录  | 一次房屋交易的信息 |
| 特征    | Feature          | 用来预测的输入变量   | 房屋面积、房龄   |
| 标签/目标 | Label/Target     | 我们想要预测的结果   | 房屋价格      |

## 数学表示

### 单个样本的预测
对于一个房子，预测公式为：
```
预测价格 = w₁ × 面积 + w₂ × 房龄 + b
```

### 通用公式
当有 d 个特征时：
```
ŷ = w₁x₁ + w₂x₂ + ... + wₐxₐ + b
```

### 向量化表示
用向量表示更简洁：
```
ŷ = w·x + b
```
其中：
- **x** 是特征向量（如 [面积, 房龄]）
- **w** 是权重向量（如 [面积权重, 房龄权重]）
- **b** 是偏置

## 线性回归要解决的问题

1. **找到最佳的权重和偏置**：使得模型预测值尽可能接近真实值
2. **处理噪声**：现实数据总有误差，需要考虑观测噪声
3. **评估模型质量**：需要一个标准来衡量模型好坏
4. **优化模型**：需要方法来不断改进模型性能

## 为什么叫"线性"？

因为预测值是特征的**线性组合**。想象一下：
- 在二维空间中，线性关系是一条直线
- 在三维空间中，线性关系是一个平面
- 在高维空间中，线性关系是一个超平面

## 实际应用场景

线性回归广泛应用于：
- **房地产**：预测房价
- **金融**：预测股价、汇率
- **零售**：预测销量
- **医疗**：预测住院时间
- **市场营销**：预测广告效果

线性回归虽然简单，但正是因为其简单性和可解释性，在实际应用中非常有效和流行。